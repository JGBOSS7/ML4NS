{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533d53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report \n",
    "from create_datasets import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb94afbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89368e58c317435fa96995a5562a72ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b610b00b5f84ffea5626ab844f4c66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e34abc744ed4fa3a042c3eb020bdd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/kanakala.ganesh/ML4NS/src/create_datasets.py:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  i[2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66aa74cb41ee4a64be39d96427d3cca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_edges = np.load('../datasets/final_edges.dump', allow_pickle=True)\n",
    "data = generate_fingerprints(final_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6512de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, n_len_seg, n_classes, device, verbose=False):\n",
    "        super(CRNN, self).__init__()\n",
    "        \n",
    "        self.n_len_seg = n_len_seg\n",
    "        self.n_classes = n_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.device = device\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # (batch, channels, length)\n",
    "        self.cnn = nn.Conv1d(in_channels=self.in_channels, \n",
    "                            out_channels=self.out_channels, \n",
    "                            kernel_size=16, \n",
    "                            stride=2)\n",
    "        # (batch, seq, feature)\n",
    "        self.rnn = nn.LSTM(input_size=(self.out_channels), \n",
    "                            hidden_size=self.out_channels, \n",
    "                            num_layers=1, \n",
    "                            batch_first=True, \n",
    "                            bidirectional=False)\n",
    "        self.dense1 = nn.Linear(out_channels, 128)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dense2 = nn.Linear(128, n_classes)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        self.n_channel, self.n_length = x.shape[-2], x.shape[-1]\n",
    "        self.n_seg = self.n_length // self.n_len_seg\n",
    "        out = x\n",
    "        out = out.permute(0,2,1)\n",
    "        out = out.view(-1, self.n_len_seg, self.n_channel)\n",
    "        out = out.permute(0,2,1)\n",
    "        out = self.cnn(out)\n",
    "        out= self.dropout1(out)\n",
    "        out = out.mean(-1)\n",
    "        out = out.view(-1, self.n_seg, self.out_channels)\n",
    "        _, (out, _) = self.rnn(out)\n",
    "        out = torch.squeeze(out, dim=0)\n",
    "        out = self.dense1(out)\n",
    "        out= self.dropout2(out)\n",
    "        out = self.dense2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0e787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNet(nn.Module):\n",
    "    def __init__(self, finger_print_model, graph_embedding_model, combined_model):\n",
    "        super().__init__()\n",
    "        self.FP_model = finger_print_model\n",
    "        self.GE_model = graph_embedding_model\n",
    "        self.CB_model = combined_model\n",
    "    \n",
    "    def forward(self, fp, ge):\n",
    "        fp_out = self.FP_model(fp)\n",
    "        ge_out = self.GE_model(ge)\n",
    "        inp = torch.cat((fp_out, ge_out), 1)\n",
    "        inp = inp.unsqueeze(1)\n",
    "        out = self.CB_model(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2fcc01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a23a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullNet(CRNN(1,256,1024,256, device), \n",
    "                CRNN(1,64,256,256, device), \n",
    "                CRNN(1,128,512,2,device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c231d3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullNet(\n",
       "  (FP_model): CRNN(\n",
       "    (cnn): Conv1d(1, 256, kernel_size=(16,), stride=(2,))\n",
       "    (rnn): LSTM(256, 256, batch_first=True)\n",
       "    (dense1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dense2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (GE_model): CRNN(\n",
       "    (cnn): Conv1d(1, 64, kernel_size=(16,), stride=(2,))\n",
       "    (rnn): LSTM(64, 64, batch_first=True)\n",
       "    (dense1): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dense2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (CB_model): CRNN(\n",
       "    (cnn): Conv1d(1, 128, kernel_size=(16,), stride=(2,))\n",
       "    (rnn): LSTM(128, 128, batch_first=True)\n",
       "    (dense1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (dropout1): Dropout(p=0.2, inplace=False)\n",
       "    (dense2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ca6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d17feb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+------------+\n",
      "|          Modules          | Parameters |\n",
      "+---------------------------+------------+\n",
      "|    FP_model.cnn.weight    |    4096    |\n",
      "|     FP_model.cnn.bias     |    256     |\n",
      "| FP_model.rnn.weight_ih_l0 |   262144   |\n",
      "| FP_model.rnn.weight_hh_l0 |   262144   |\n",
      "|  FP_model.rnn.bias_ih_l0  |    1024    |\n",
      "|  FP_model.rnn.bias_hh_l0  |    1024    |\n",
      "|   FP_model.dense1.weight  |   32768    |\n",
      "|    FP_model.dense1.bias   |    128     |\n",
      "|   FP_model.dense2.weight  |   32768    |\n",
      "|    FP_model.dense2.bias   |    256     |\n",
      "|    GE_model.cnn.weight    |    1024    |\n",
      "|     GE_model.cnn.bias     |     64     |\n",
      "| GE_model.rnn.weight_ih_l0 |   16384    |\n",
      "| GE_model.rnn.weight_hh_l0 |   16384    |\n",
      "|  GE_model.rnn.bias_ih_l0  |    256     |\n",
      "|  GE_model.rnn.bias_hh_l0  |    256     |\n",
      "|   GE_model.dense1.weight  |    8192    |\n",
      "|    GE_model.dense1.bias   |    128     |\n",
      "|   GE_model.dense2.weight  |   32768    |\n",
      "|    GE_model.dense2.bias   |    256     |\n",
      "|    CB_model.cnn.weight    |    2048    |\n",
      "|     CB_model.cnn.bias     |    128     |\n",
      "| CB_model.rnn.weight_ih_l0 |   65536    |\n",
      "| CB_model.rnn.weight_hh_l0 |   65536    |\n",
      "|  CB_model.rnn.bias_ih_l0  |    512     |\n",
      "|  CB_model.rnn.bias_hh_l0  |    512     |\n",
      "|   CB_model.dense1.weight  |   16384    |\n",
      "|    CB_model.dense1.bias   |    128     |\n",
      "|   CB_model.dense2.weight  |    256     |\n",
      "|    CB_model.dense2.bias   |     2      |\n",
      "+---------------------------+------------+\n",
      "Total Trainable Params: 823362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "823362"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b986ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LinkDataset(data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train , test = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "BATCH_SIZE = 512\n",
    "trainloader = DataLoader(train, num_workers = 16, batch_size= BATCH_SIZE, shuffle=True)\n",
    "testloader = DataLoader(test, num_workers = 16, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4be3da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bee88c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for fp, ge, label in testloader:\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        test_loss+=loss.item()\n",
    "        for i in range(len(output)):\n",
    "            pred = output[i].argmax().item()\n",
    "            true = label[i].argmax().item()\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "    model.train()\n",
    "    print(\"Accuracy\", accuracy_score(preds, trues))\n",
    "    return test_loss / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835db4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5b8e3c06a8402ba9dc3bb4164e1466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 batch 137/137 loss:0.7015280723571777\r"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "num_epochs= 50\n",
    "for epoch in tqdm(range(1, num_epochs)):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    batch_id = 0\n",
    "    for fp, ge, label in trainloader:\n",
    "        batch_id +=1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "    \n",
    "        print(f'Epoch:{epoch} batch {batch_id}/{len(trainloader)} loss:{loss.item()}', end='\\r')\n",
    "    \n",
    "    test_loss = eval(model, testloader)\n",
    "    print()\n",
    "    print(\"Train loss: \",train_loss/len(trainloader))\n",
    "    print(\"Test  loss: \",test_loss)\n",
    "    \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1d42c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f2f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f01cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20fbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
