{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02487496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from create_datasets import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07203f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_edges = np.load('../datasets/final_edges.dump', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee2b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e35a25dc7ce4b82a78f18e2539b53c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20508607c0b4511ba0da4d70b67bf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d505db90028b4a2fa075be4de3fe619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/kanakala.ganesh/ML4NS/src/create_datasets.py:54: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  i[2] ]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eddc95ea11614960b9f50f6f4ec5f319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = generate_fingerprints(final_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bcee7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN_net(nn.Module):\n",
    "    def __init__(self, inp_len=1024, out_len = 256, in_c=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(inp_len, 4056)\n",
    "        self.fc2 = nn.Linear(4056, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 512)\n",
    "        self.dp = nn.Dropout(0.2)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, out_len),\n",
    "#             nn.Softmax(0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x=  self.dp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x=  self.dp(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "899bb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN_net(nn.Module):\n",
    "#     def __init__(self, inp_len=1024, out_len = 256, in_c=1):\n",
    "#         super().__init__()\n",
    "#         self.conv_block1 = nn.Sequential(\n",
    "#             nn.Conv1d(in_c, 64, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.1)\n",
    "#         )\n",
    "        \n",
    "#         self.conv_block2 = nn.Sequential(\n",
    "#             nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.2)\n",
    "#         )\n",
    "#         self.conv_block3 = nn.Sequential(\n",
    "#             nn.Conv1d(128, 256, kernel_size=7, stride=1, padding=3),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.3)\n",
    "#         )\n",
    "# #         self.conv_block4 = nn.Sequential(\n",
    "# #             nn.Conv1d(256, 512, kernel_size=9, stride=1, padding=4),\n",
    "# #             nn.BatchNorm1d(512),\n",
    "# #             nn.ReLU(),\n",
    "# #             nn.Dropout(0.4)\n",
    "# #         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(256*inp_len, 128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 32),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(32, out_len)\n",
    "            \n",
    "#         )\n",
    "\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv_block1(x)\n",
    "#         x = self.conv_block2(x)\n",
    "#         x = self.conv_block3(x)\n",
    "# #         x = self.conv_block4(x)\n",
    "#         x = x.view(x.size(0), -1) # flat\n",
    "#         x = self.decoder(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b5b80689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNet(nn.Module):\n",
    "    def __init__(self, finger_print_model, graph_embedding_model, combined_model):\n",
    "        super().__init__()\n",
    "        self.FP_model = finger_print_model\n",
    "        self.GE_model = graph_embedding_model\n",
    "        self.CB_model = combined_model\n",
    "    \n",
    "    def forward(self, fp, ge):\n",
    "        fp_out = self.FP_model(fp)\n",
    "        ge_out = self.GE_model(ge)\n",
    "#         print(ge_out.shape)\n",
    "        inp = torch.cat((fp_out, ge_out), 1)\n",
    "#         inp = inp.unsqueeze(1)\n",
    "#         print(inp.shape)\n",
    "        out = self.CB_model(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "17124762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "a026be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b0feb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LinkDataset(data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train , test = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "BATCH_SIZE = 256\n",
    "trainloader = DataLoader(train, num_workers = 16, batch_size= BATCH_SIZE)\n",
    "testloader = DataLoader(test, num_workers = 16, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b1246eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullNet(FNN_net(inp_len=1024, out_len=256), \n",
    "                FNN_net(inp_len=256, out_len =256), \n",
    "                FNN_net(inp_len=512, out_len = 2))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "afc23c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullNet(\n",
       "  (FP_model): FNN_net(\n",
       "    (fc1): Linear(in_features=1024, out_features=4056, bias=True)\n",
       "    (fc2): Linear(in_features=4056, out_features=2048, bias=True)\n",
       "    (fc3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (dp): Dropout(p=0.2, inplace=False)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=32, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GE_model): FNN_net(\n",
       "    (fc1): Linear(in_features=256, out_features=4056, bias=True)\n",
       "    (fc2): Linear(in_features=4056, out_features=2048, bias=True)\n",
       "    (fc3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (dp): Dropout(p=0.2, inplace=False)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=32, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (CB_model): FNN_net(\n",
       "    (fc1): Linear(in_features=512, out_features=4056, bias=True)\n",
       "    (fc2): Linear(in_features=4056, out_features=2048, bias=True)\n",
       "    (fc3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (dp): Dropout(p=0.2, inplace=False)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "102deaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model(torch.rand(32, 1, 1024).float().to(device), torch.rand(32, 1, 256).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "45246190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bf559da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 11 12:54:25 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 29%   51C    P2    59W / 250W |    999MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   25C    P8     9W / 250W |      4MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 31%   26C    P8     9W / 250W |      4MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:83:00.0 Off |                  N/A |\n",
      "| 23%   26C    P8     9W / 250W |      4MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7457      C   ...nda3/envs/fast/bin/python      995MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "8a08a6cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+------------+\n",
      "|          Modules          | Parameters |\n",
      "+---------------------------+------------+\n",
      "|    FP_model.fc1.weight    |  4153344   |\n",
      "|     FP_model.fc1.bias     |    4056    |\n",
      "|    FP_model.fc2.weight    |  8306688   |\n",
      "|     FP_model.fc2.bias     |    2048    |\n",
      "|    FP_model.fc3.weight    |  1048576   |\n",
      "|     FP_model.fc3.bias     |    512     |\n",
      "| FP_model.decoder.0.weight |   131072   |\n",
      "|  FP_model.decoder.0.bias  |    256     |\n",
      "| FP_model.decoder.2.weight |    8192    |\n",
      "|  FP_model.decoder.2.bias  |     32     |\n",
      "| FP_model.decoder.4.weight |    8192    |\n",
      "|  FP_model.decoder.4.bias  |    256     |\n",
      "|    GE_model.fc1.weight    |  1038336   |\n",
      "|     GE_model.fc1.bias     |    4056    |\n",
      "|    GE_model.fc2.weight    |  8306688   |\n",
      "|     GE_model.fc2.bias     |    2048    |\n",
      "|    GE_model.fc3.weight    |  1048576   |\n",
      "|     GE_model.fc3.bias     |    512     |\n",
      "| GE_model.decoder.0.weight |   131072   |\n",
      "|  GE_model.decoder.0.bias  |    256     |\n",
      "| GE_model.decoder.2.weight |    8192    |\n",
      "|  GE_model.decoder.2.bias  |     32     |\n",
      "| GE_model.decoder.4.weight |    8192    |\n",
      "|  GE_model.decoder.4.bias  |    256     |\n",
      "|    CB_model.fc1.weight    |  2076672   |\n",
      "|     CB_model.fc1.bias     |    4056    |\n",
      "|    CB_model.fc2.weight    |  8306688   |\n",
      "|     CB_model.fc2.bias     |    2048    |\n",
      "|    CB_model.fc3.weight    |  1048576   |\n",
      "|     CB_model.fc3.bias     |    512     |\n",
      "| CB_model.decoder.0.weight |   131072   |\n",
      "|  CB_model.decoder.0.bias  |    256     |\n",
      "| CB_model.decoder.2.weight |    8192    |\n",
      "|  CB_model.decoder.2.bias  |     32     |\n",
      "| CB_model.decoder.4.weight |     64     |\n",
      "|  CB_model.decoder.4.bias  |     2      |\n",
      "+---------------------------+------------+\n",
      "Total Trainable Params: 35789610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35789610"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7a197d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for fp, ge, label in testloader:\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        test_loss+=loss.item()\n",
    "        for i in range(len(output)):\n",
    "            pred = output[i].argmax().item()\n",
    "            true = label[i].argmax().item()\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "    model.train()\n",
    "    print(\"Accuracy\", accuracy_score(preds, trues))\n",
    "    return accuracy_score(preds, trues), test_loss / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "0e98ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "49c5935d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7c7e76febc4ebfa4ac2569688897bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.66014571740003450.6789695024490356\n",
      "Improved Accuracy is 0.6601457174000345\n",
      "\n",
      "Train loss:  0.6760997082287575\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.66014571740003450.6765668988227844\n",
      "\n",
      "Train loss:  0.6625865745893765\n",
      "Test  loss:  0.6584765859272169\n",
      "Accuracy 0.66014571740003450.6788615584373474\n",
      "\n",
      "Train loss:  0.668295851338914\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.66014571740003450.6803316473960876\n",
      "\n",
      "Train loss:  0.6682926342164204\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.66014571740003450.6795712113380432\n",
      "\n",
      "Train loss:  0.6683242908327571\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.66014571740003450.6793715953826904\n",
      "\n",
      "Train loss:  0.668303329866011\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.66014571740003450.6795013546943665\n",
      "\n",
      "Train loss:  0.6683069533044166\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.66014571740003450.6802973747253418\n",
      "\n",
      "Train loss:  0.6682676439320211\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.66014571740003450.6803066730499268\n",
      "\n",
      "Train loss:  0.6682777219202929\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6793089509010315\n",
      "\n",
      "Train loss:  0.6683469997657524\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6779007911682129\n",
      "\n",
      "Train loss:  0.6682568454480433\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6822027564048767\n",
      "\n",
      "Train loss:  0.6683228965643998\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6794478297233582\n",
      "\n",
      "Train loss:  0.6683637757441063\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6790859103202824\n",
      "\n",
      "Train loss:  0.6682589263706417\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6802458167076111\n",
      "\n",
      "Train loss:  0.6683364892617251\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6796132326126099\n",
      "\n",
      "Train loss:  0.6682954330147405\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6788780689239502\n",
      "\n",
      "Train loss:  0.668304002110338\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6794749498367312\n",
      "\n",
      "Train loss:  0.6682896581324902\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6798504590988159\n",
      "\n",
      "Train loss:  0.6683402026529277\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6809603571891785\n",
      "\n",
      "Train loss:  0.6683421093465645\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6796346306800842\n",
      "\n",
      "Train loss:  0.668339111429431\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6792083978652954\n",
      "\n",
      "Train loss:  0.6683571284070556\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6785106658935547\n",
      "\n",
      "Train loss:  0.6682854037145118\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6764674186706543\n",
      "\n",
      "Train loss:  0.668300768831274\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6796039342880249\n",
      "\n",
      "Train loss:  0.6683564945891664\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6804669499397278\n",
      "\n",
      "Train loss:  0.6682872158703786\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6789307594299316\n",
      "\n",
      "Train loss:  0.6682578871101686\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6779950261116028\n",
      "\n",
      "Train loss:  0.6683193397172641\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6800059676170349\n",
      "\n",
      "Train loss:  0.6682634851434729\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6799421310424805\n",
      "\n",
      "Train loss:  0.668322871237884\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6793904304504395\n",
      "\n",
      "Train loss:  0.6682936184572212\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6784371733665466\n",
      "\n",
      "Train loss:  0.6683021397381038\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6803764104843146\n",
      "\n",
      "Train loss:  0.6683691633053315\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6797983646392822\n",
      "\n",
      "Train loss:  0.668341508933476\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6803210973739624\n",
      "\n",
      "Train loss:  0.6682726129507407\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6796861290931702\n",
      "\n",
      "Train loss:  0.6682861196252453\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6786264777183533\n",
      "\n",
      "Train loss:  0.6683940651652577\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6784690022468567\n",
      "\n",
      "Train loss:  0.66832190599197\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6816350221633911\n",
      "\n",
      "Train loss:  0.6683455677259535\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6774297952651978\n",
      "\n",
      "Train loss:  0.6682878752331157\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6806024312973022\n",
      "\n",
      "Train loss:  0.6683007094449612\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6806732416152954\n",
      "\n",
      "Train loss:  0.6682605197578123\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6806243062019348\n",
      "\n",
      "Train loss:  0.6682071995822502\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6783865094184875\n",
      "\n",
      "Train loss:  0.6683207839836568\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6817998886108398\n",
      "\n",
      "Train loss:  0.6683085091384776\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6785919666290283\n",
      "\n",
      "Train loss:  0.6682957135714017\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6776466965675354\n",
      "\n",
      "Train loss:  0.6683279778057839\n",
      "Test  loss:  0.6689197792523149\n",
      "Accuracy 0.6601457174000345:0.6808746457099915\n",
      "\n",
      "Train loss:  0.6682889306501592\n",
      "Test  loss:  0.6689197792523149\n",
      "Epoch:49 batch 257/273 loss:0.6702426075935364\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-d8c501adedf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_id\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fast/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    215\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "num_epochs= 50\n",
    "best_acc = 0.0\n",
    "acc_list = []\n",
    "for epoch in tqdm(range(1, num_epochs)):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    batch_id = 0\n",
    "    for fp, ge, label in trainloader:\n",
    "        batch_id +=1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        \n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "    \n",
    "        print(f'Epoch:{epoch} batch {batch_id}/{len(trainloader)} loss:{loss.item()}', end='\\r')\n",
    "    \n",
    "    acc, test_loss = eval(model, testloader)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        print(\"Improved Accuracy is\", acc )\n",
    "        torch.save(model, 'SAVED_MODELS/FNN-bestmodel_1.pt')\n",
    "        \n",
    "        with open('SAVED_MODELS/FNN-bestmodel_1.txt', 'w') as f:\n",
    "            print(model.eval() , \"Accuracy\" , acc, file=f)\n",
    "\n",
    "    else:\n",
    "        model = torch.load('SAVED_MODELS/FNN-bestmodel_1.pt')\n",
    "    \n",
    "    print()\n",
    "    print(\"Train loss: \",train_loss/len(trainloader))\n",
    "    print(\"Test  loss: \",test_loss)\n",
    "    \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8856635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F.normalize(output,1)\n",
    "# output\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del trainloader\n",
    "# del testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048de867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)\n",
    "plt.plot(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('SAVED_MODELS/FNN-bestmodel_1.pt')\n",
    "eval(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "def get_performance(model, testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for fp, ge, label in testloader:\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        test_loss+=loss.item()\n",
    "        for i in range(len(output)):\n",
    "            pred = output[i].argmax().item()\n",
    "            true = label[i].argmax().item()\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "    model.train()\n",
    "    print(\"Accuracy\", accuracy_score(preds, trues))\n",
    "    print(\"f1 score\", f1_score(preds, trues))\n",
    "    print(classification_report(trues, preds, labels=[0,1]))\n",
    "    print()\n",
    "    cm = confusion_matrix(trues, preds, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(cm, np.array([0,1]))\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ef59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6873ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'CNN-model-acc-0.888.pt')\n",
    "# with open('CNN-model-acc-0.888.txt', 'w') as f:\n",
    "#     print(model.eval(), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c67027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e75fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
