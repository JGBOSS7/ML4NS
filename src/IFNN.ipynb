{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c9f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from create_datasets import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35965627",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_edges = np.load('../datasets/final_edges.dump', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf387e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc43b95d177f4120a4a7bbea55ebb6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = generate_fingerprints(final_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6e3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN_net(nn.Module):\n",
    "    def __init__(self, inp_len=1024, out_len = 256, in_c=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(inp_len, 4056)\n",
    "        self.fc2 = nn.Linear(4056, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 512)\n",
    "        self.dp = nn.Dropout(0.2)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, out_len),\n",
    "#             nn.Softmax(0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x= torch.squeeze(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x=  self.dp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x=  self.dp(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        \n",
    "        x = self.decoder(x)\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fabefa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNet(nn.Module):\n",
    "    def __init__(self, finger_print_model, graph_embedding_model, combined_model):\n",
    "        super().__init__()\n",
    "        self.FP_model = finger_print_model\n",
    "        self.GE_model = graph_embedding_model\n",
    "        self.CB_model = combined_model\n",
    "    \n",
    "    def forward(self, fp, ge):\n",
    "        fp_out = self.FP_model(fp)\n",
    "        ge_out = self.GE_model(ge)\n",
    "#         print(ge_out.shape)\n",
    "        inp = torch.cat((fp_out, ge_out), 1)\n",
    "#         inp = inp.unsqueeze(1)\n",
    "#         print(inp.shape)\n",
    "        out = self.CB_model(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834d95ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8afdbb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LinkDataset(data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train , test = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "BATCH_SIZE = 256\n",
    "trainloader = DataLoader(train, num_workers = 16, batch_size= BATCH_SIZE)\n",
    "testloader = DataLoader(test, num_workers = 16, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5ba8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullNet(FNN_net(inp_len=1024, out_len=256), \n",
    "                FNN_net(inp_len=256, out_len =256), \n",
    "                FNN_net(inp_len=512, out_len = 2))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-5)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96772f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullNet(\n",
       "  (FP_model): FNN_net(\n",
       "    (fc1): Linear(in_features=1024, out_features=4056, bias=True)\n",
       "    (fc2): Linear(in_features=4056, out_features=2048, bias=True)\n",
       "    (fc3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (dp): Dropout(p=0.2, inplace=False)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=32, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (GE_model): FNN_net(\n",
       "    (fc1): Linear(in_features=256, out_features=4056, bias=True)\n",
       "    (fc2): Linear(in_features=4056, out_features=2048, bias=True)\n",
       "    (fc3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (dp): Dropout(p=0.2, inplace=False)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=32, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (CB_model): FNN_net(\n",
       "    (fc1): Linear(in_features=512, out_features=4056, bias=True)\n",
       "    (fc2): Linear(in_features=4056, out_features=2048, bias=True)\n",
       "    (fc3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (dp): Dropout(p=0.2, inplace=False)\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=32, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b33e7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 17 15:17:21 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   36C    P2    57W / 250W |    965MiB / 11178MiB |      8%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     32547      C   ....ganesh/miniconda3/envs/fast/bin/python   955MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3997c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+------------+\n",
      "|          Modules          | Parameters |\n",
      "+---------------------------+------------+\n",
      "|    FP_model.fc1.weight    |  4153344   |\n",
      "|     FP_model.fc1.bias     |    4056    |\n",
      "|    FP_model.fc2.weight    |  8306688   |\n",
      "|     FP_model.fc2.bias     |    2048    |\n",
      "|    FP_model.fc3.weight    |  1048576   |\n",
      "|     FP_model.fc3.bias     |    512     |\n",
      "| FP_model.decoder.0.weight |   131072   |\n",
      "|  FP_model.decoder.0.bias  |    256     |\n",
      "| FP_model.decoder.2.weight |    8192    |\n",
      "|  FP_model.decoder.2.bias  |     32     |\n",
      "| FP_model.decoder.4.weight |    8192    |\n",
      "|  FP_model.decoder.4.bias  |    256     |\n",
      "|    GE_model.fc1.weight    |  1038336   |\n",
      "|     GE_model.fc1.bias     |    4056    |\n",
      "|    GE_model.fc2.weight    |  8306688   |\n",
      "|     GE_model.fc2.bias     |    2048    |\n",
      "|    GE_model.fc3.weight    |  1048576   |\n",
      "|     GE_model.fc3.bias     |    512     |\n",
      "| GE_model.decoder.0.weight |   131072   |\n",
      "|  GE_model.decoder.0.bias  |    256     |\n",
      "| GE_model.decoder.2.weight |    8192    |\n",
      "|  GE_model.decoder.2.bias  |     32     |\n",
      "| GE_model.decoder.4.weight |    8192    |\n",
      "|  GE_model.decoder.4.bias  |    256     |\n",
      "|    CB_model.fc1.weight    |  2076672   |\n",
      "|     CB_model.fc1.bias     |    4056    |\n",
      "|    CB_model.fc2.weight    |  8306688   |\n",
      "|     CB_model.fc2.bias     |    2048    |\n",
      "|    CB_model.fc3.weight    |  1048576   |\n",
      "|     CB_model.fc3.bias     |    512     |\n",
      "| CB_model.decoder.0.weight |   131072   |\n",
      "|  CB_model.decoder.0.bias  |    256     |\n",
      "| CB_model.decoder.2.weight |    8192    |\n",
      "|  CB_model.decoder.2.bias  |     32     |\n",
      "| CB_model.decoder.4.weight |     64     |\n",
      "|  CB_model.decoder.4.bias  |     2      |\n",
      "+---------------------------+------------+\n",
      "Total Trainable Params: 35789610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35789610"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb142da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for fp, ge, label in testloader:\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        test_loss+=loss.item()\n",
    "        for i in range(len(output)):\n",
    "            pred = output[i].argmax().item()\n",
    "            true = label[i].argmax().item()\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "    model.train()\n",
    "    print(\"Accuracy\", accuracy_score(preds, trues))\n",
    "    return accuracy_score(preds, trues), test_loss / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57ce4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1802e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "num_epochs= 50\n",
    "best_acc = 0.0\n",
    "acc_list = []\n",
    "for epoch in tqdm(range(1, num_epochs)):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    batch_id = 0\n",
    "    for fp, ge, label in trainloader:\n",
    "        batch_id +=1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        \n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "    \n",
    "        print(f'Epoch:{epoch} batch {batch_id}/{len(trainloader)} loss:{loss.item()}', end='\\r')\n",
    "    \n",
    "    acc, test_loss = eval(model, testloader)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        print(\"Improved Accuracy is\", acc )\n",
    "#         torch.save(model, 'SAVED_MODELS/FNN-bestmodel_1.pt')\n",
    "        \n",
    "#         with open('SAVED_MODELS/FNN-bestmodel_1.txt', 'w') as f:\n",
    "#             print(model.eval() , \"Accuracy\" , acc, file=f)\n",
    "\n",
    "    else:\n",
    "#         model = torch.load('SAVED_MODELS/FNN-bestmodel_1.pt')\n",
    "    \n",
    "    print()\n",
    "    print(\"Train loss: \",train_loss/len(trainloader))\n",
    "    print(\"Test  loss: \",test_loss)\n",
    "    \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    test_losses.append(test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
