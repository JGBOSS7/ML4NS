{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02487496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "from create_datasets import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07203f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_edges = np.load('../datasets/final_edges.dump', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4557637f7ba408d94173ebe9cddfc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87153 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = generate_fingerprints(final_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_net(nn.Module):\n",
    "    def __init__(self, inp_len=1024, out_len = 256, in_c=1):\n",
    "        super().__init__()\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_c, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=7, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256*inp_len, 512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(512, out_len),\n",
    "#             nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = x.view(x.size(0), -1) # flat\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b80689",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullNet(nn.Module):\n",
    "    def __init__(self, finger_print_model, graph_embedding_model, combined_model):\n",
    "        super().__init__()\n",
    "        self.FP_model = finger_print_model\n",
    "        self.GE_model = graph_embedding_model\n",
    "        self.CB_model = combined_model\n",
    "    \n",
    "    def forward(self, fp, ge):\n",
    "        fp_out = self.FP_model(fp)\n",
    "        ge_out = self.GE_model(ge)\n",
    "        inp = torch.cat((fp_out, ge_out), 1)\n",
    "        inp = inp.unsqueeze(1)\n",
    "        out = self.CB_model(inp)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17124762",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026be76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0feb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LinkDataset(data)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train , test = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "BATCH_SIZE = 256\n",
    "trainloader = DataLoader(train, num_workers = 16, batch_size= BATCH_SIZE)\n",
    "testloader = DataLoader(test, num_workers = 16, batch_size= BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1246eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullNet(CNN_net(inp_len=1024, out_len=256), \n",
    "                CNN_net(inp_len=256, out_len =256), \n",
    "                CNN_net(inp_len=512, out_len = 2))\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-6\n",
    "                            )\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cba34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.rand(32, 1, 1024).float().to(device), torch.rand(32, 1, 256).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf559da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a197d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for fp, ge, label in testloader:\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        test_loss+=loss.item()\n",
    "        for i in range(len(output)):\n",
    "            pred = output[i].argmax().item()\n",
    "            true = label[i].argmax().item()\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "    model.train()\n",
    "    print(\"Accuracy\", accuracy_score(preds, trues))\n",
    "    return accuracy_score(preds, trues), test_loss / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5935d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "num_epochs= 50\n",
    "best_acc = 0.0\n",
    "acc_list = []\n",
    "for epoch in tqdm(range(1, num_epochs)):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    batch_id = 0\n",
    "    for fp, ge, label in trainloader:\n",
    "        batch_id +=1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() \n",
    "    \n",
    "        print(f'Epoch:{epoch} batch {batch_id}/{len(trainloader)} loss:{loss.item()}', end='\\r')\n",
    "    \n",
    "    acc, test_loss = eval(model, testloader)\n",
    "    acc_list.append(acc)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        print(\"Improved Accuracy is\", acc )\n",
    "        torch.save(model, 'SAVED_MODELS/CNN-bestmodel_4.pt')\n",
    "        with open('SAVED_MODELS/CNN-bestmodel_4.txt', 'w') as f:\n",
    "            print(model.eval() , \"Accuracy\" , acc, file=f)\n",
    "\n",
    "#     else:\n",
    "#         model = torch.load('SAVED_MODELS/CNN-bestmodel_3.pt')\n",
    "    \n",
    "    print()\n",
    "    print(\"Train loss: \",train_loss/len(trainloader))\n",
    "    print(\"Test  loss: \",test_loss)\n",
    "    \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048de867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('SAVED_MODELS/CNN-bestmodel_4.pt')\n",
    "# eval(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef01a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "def get_performance(model, testloader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    preds = []\n",
    "    trues = []\n",
    "    for fp, ge, label in testloader:\n",
    "        output = model(fp.float().to(device),ge.float().to(device))\n",
    "        loss = criterion(output, label.float().to(device))\n",
    "        test_loss+=loss.item()\n",
    "        for i in range(len(output)):\n",
    "            pred = output[i].argmax().item()\n",
    "            true = label[i].argmax().item()\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "    model.train()\n",
    "    print(\"Accuracy\", accuracy_score(preds, trues))\n",
    "    print(\"f1 score\", f1_score(preds, trues))\n",
    "    print(classification_report(trues, preds, labels=[0,1]))\n",
    "    print()\n",
    "    cm = confusion_matrix(trues, preds, labels=[0,1])\n",
    "    disp = ConfusionMatrixDisplay(cm, np.array([0,1]))\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56bc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_performance(model, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6873ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'CNN-model-acc-0.888.pt')\n",
    "# with open('CNN-model-acc-0.888.txt', 'w') as f:\n",
    "#     print(model.eval(), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc18f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f351b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "num_epochs = 1\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# For fold results\n",
    "results = {}\n",
    "\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    \n",
    "    print(f'FOLD {fold}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=128, sampler=train_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=128, sampler=test_subsampler)\n",
    "    \n",
    "    model = FullNet(CNN_net(inp_len=1024, out_len=256), \n",
    "                CNN_net(inp_len=256, out_len =256), \n",
    "                CNN_net(inp_len=512, out_len = 2))\n",
    "    \n",
    "    model.apply(reset_weights)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "    \n",
    "    for epoch in range(0, num_epochs):\n",
    "        \n",
    "        print(f'Starting epoch {epoch+1}')\n",
    "        current_loss = 0.0\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        batch_id = 0\n",
    "        for fp, ge, label in trainloader:\n",
    "            batch_id +=1\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            output = model(fp.float().to(device),ge.float().to(device))\n",
    "            loss = criterion(output, label.float().to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() \n",
    "    \n",
    "            print(f'Epoch:{epoch} batch {batch_id}/{len(trainloader)} loss:{loss.item()}', end='\\r')\n",
    "        \n",
    "    print('Training process has finished. Saving trained model.')\n",
    "    print('Starting testing')\n",
    "    \n",
    "    # Saving the model\n",
    "    save_path = f'./model-fold-{fold}.pth'\n",
    "    torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # Evaluationfor this fold\n",
    "    acc, test_loss = eval(model, testloader)\n",
    "    results[fold] = acc * 100\n",
    "\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "sum = 0.0\n",
    "for key, value in results.items():\n",
    "    print(f'Fold {key}: {value} %')\n",
    "    sum += value\n",
    "print(f'Average: {sum/len(results.items())} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
